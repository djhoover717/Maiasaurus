{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT STATEMENTS AND PRELIMINARIES\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from astropy.constants import R_earth\n",
    "from astropy.constants import R_jup\n",
    "\n",
    "RERJ = float(R_earth/R_jup)\n",
    "\n",
    "\n",
    "pi = np.pi\n",
    "\n",
    "MAINPATH = '/Users/research/projects/oviraptor/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in exoarchive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file names\n",
    "planet_file = MAINPATH + \"catalogues/exoarchive_ipac_confirmed_20201008.csv\"\n",
    "\n",
    "# convenience function to read in csv file\n",
    "def read_csv_file(filename):\n",
    "    data = []\n",
    "    with open(filename) as infile:\n",
    "        reader = csv.reader(infile)\n",
    "\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "\n",
    "        keys   = data[97]\n",
    "        values = data[98:]\n",
    "            \n",
    "        return keys, values\n",
    "\n",
    "\n",
    "# READ IN DR25 DATABASE -- https://exoplanetarchive.ipac.caltech.edu\n",
    "csv_keys, csv_data = read_csv_file(planet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience functions to pull data from csv files\n",
    "def getdata(keyname,keys=csv_keys,data=csv_data):\n",
    "    '''\n",
    "    keyname = (string) of column definition, see CKS documentation\n",
    "    '''\n",
    "    kid = keys.index(keyname)\n",
    "    \n",
    "    outdata = []\n",
    "    for row in data:\n",
    "        outdata.append(row[kid])\n",
    "    \n",
    "    return outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into a dictionary\n",
    "data = {}\n",
    "for k in csv_keys:\n",
    "    data[k] = getdata(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of queried objects = 4292\n"
     ]
    }
   ],
   "source": [
    "def check_lengths(data):\n",
    "    keys = data.keys()\n",
    "    k0   = list(keys)[0]\n",
    "    L0   = len(data[k0])\n",
    "    \n",
    "    for k in keys:\n",
    "        if len(data[k]) != L0:\n",
    "            raise ValueError('inconsistent array lengths')\n",
    "            \n",
    "    return None\n",
    "\n",
    "\n",
    "def convert_to_arrays(data):\n",
    "    keys = data.keys()\n",
    "    dnew = {}\n",
    "    \n",
    "    for k in keys:\n",
    "        dnew[k] = np.asarray(data[k])\n",
    "        \n",
    "    return dnew       \n",
    "\n",
    "\n",
    "\n",
    "# grab a reference key\n",
    "k0 = list(data.keys())[0]\n",
    "\n",
    "\n",
    "# convert to arrays\n",
    "data = convert_to_arrays(data)\n",
    "print('total number of queried objects =', len(data[k0]))\n",
    "\n",
    "\n",
    "check_lengths(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unwanted objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 185 objects due to non-relevant DETECTION METHOD\n",
      "removed 10 objects flagged as CONTROVERSIAL\n",
      "\n",
      "after cuts, 4097 objects remain\n",
      "\n",
      "3264 TRANSITING planets\n",
      "812 RADIAL VELOCITY planets\n",
      "21 TTV planets\n"
     ]
    }
   ],
   "source": [
    "# filter detection methods\n",
    "keep = (data[\"discoverymethod\"] == \"Transit\") + (data[\"discoverymethod\"] == \"Radial Velocity\") + \\\n",
    "       (data[\"discoverymethod\"] == \"Transit Timing Variations\")\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][keep]\n",
    "\n",
    "print(\"removed {0} objects due to non-relevant DETECTION METHOD\".format(np.sum(~keep)))\n",
    "\n",
    "\n",
    "# controversial flag\n",
    "bad = data[\"pl_controv_flag\"] == \"1\"\n",
    "\n",
    "for k in data.keys():\n",
    "    data[k] = data[k][~bad]\n",
    "\n",
    "print(\"removed {0} objects flagged as CONTROVERSIAL\".format(np.sum(bad)))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nafter cuts, {0} objects remain\\n\".format(len(data[k0])))\n",
    "\n",
    "print(\"{0} TRANSITING planets\".format(np.sum(data[\"discoverymethod\"] == \"Transit\")))\n",
    "print(\"{0} RADIAL VELOCITY planets\".format(np.sum(data[\"discoverymethod\"] == \"Radial Velocity\")))\n",
    "print(\"{0} TTV planets\".format(np.sum(data[\"discoverymethod\"] == \"Transit Timing Variations\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pl_name', 'hostname', 'default_flag', 'sy_snum', 'sy_pnum', 'discoverymethod', 'disc_year', 'disc_facility', 'soltype', 'pl_controv_flag', 'pl_refname', 'pl_orbper', 'pl_orbpererr1', 'pl_orbpererr2', 'pl_orbperlim', 'pl_orbsmax', 'pl_orbsmaxerr1', 'pl_orbsmaxerr2', 'pl_orbsmaxlim', 'pl_rade', 'pl_radeerr1', 'pl_radeerr2', 'pl_radelim', 'pl_radj', 'pl_radjerr1', 'pl_radjerr2', 'pl_radjlim', 'pl_bmasse', 'pl_bmasseerr1', 'pl_bmasseerr2', 'pl_bmasselim', 'pl_bmassj', 'pl_bmassjerr1', 'pl_bmassjerr2', 'pl_bmassjlim', 'pl_bmassprov', 'pl_orbeccen', 'pl_orbeccenerr1', 'pl_orbeccenerr2', 'pl_orbeccenlim', 'pl_insol', 'pl_insolerr1', 'pl_insolerr2', 'pl_insollim', 'pl_eqt', 'pl_eqterr1', 'pl_eqterr2', 'pl_eqtlim', 'ttv_flag', 'st_refname', 'st_teff', 'st_tefferr1', 'st_tefferr2', 'st_tefflim', 'st_rad', 'st_raderr1', 'st_raderr2', 'st_radlim', 'st_mass', 'st_masserr1', 'st_masserr2', 'st_masslim', 'st_met', 'st_meterr1', 'st_meterr2', 'st_metlim', 'st_metratio', 'st_logg', 'st_loggerr1', 'st_loggerr2', 'st_logglim', 'sy_refname', 'rastr', 'ra', 'decstr', 'dec', 'sy_dist', 'sy_disterr1', 'sy_disterr2', 'sy_vmag', 'sy_vmagerr1', 'sy_vmagerr2', 'sy_kmag', 'sy_kmagerr1', 'sy_kmagerr2', 'sy_gaiamag', 'sy_gaiamagerr1', 'sy_gaiamagerr2', 'rowupdate', 'pl_pubdate', 'releasedate'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check stellar parameter consistency for each system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "npl = np.array(data[\"sy_pnum\"], dtype=\"int\")\n",
    "\n",
    "starname = np.array(data[\"hostname\"])\n",
    "detmet = np.array(data[\"discoverymethod\"])\n",
    "Mstar = np.array(data[\"st_mass\"])\n",
    "Rstar = np.array(data[\"st_rad\"])\n",
    "\n",
    "uniquesys = np.unique(starname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# some planets have no stellar mass/radius given; others have a value for only a single planet in a system\n",
    "# for multis where one planet has a stellar mass/radius value, broadcast this to all planets in the system\n",
    "for i, s in enumerate(uniquesys):\n",
    "    use = starname == s\n",
    "    \n",
    "    # first fix stellar masses\n",
    "    if np.any(Mstar[use] == \"\"):\n",
    "        unique_ms = np.unique(Mstar[use])\n",
    "        \n",
    "        if len(unique_ms) == 2:\n",
    "            Mstar[use] = str(unique_ms[unique_ms != ''].item())\n",
    "    \n",
    "    # then fix stellar radii\n",
    "    if np.any(Rstar[use] == \"\"):\n",
    "        unique_rs = np.unique(Rstar[use])\n",
    "        \n",
    "        if len(unique_rs) == 2:\n",
    "            Rstar[use] = str(unique_rs[unique_rs != ''].item())            \n",
    "            \n",
    "\n",
    "data[\"st_mass\"] = np.copy(Mstar)\n",
    "data[\"st_rad\"] = np.copy(Rstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Missing MASS\n",
      "['GJ 163']\n",
      "\n",
      "\n",
      "Missing RADIUS\n",
      "['GJ 163' 'GJ 180' 'GJ 433' 'GJ 667 C' 'HD 133131 A' 'HD 133131 B'\n",
      " 'HD 136352' 'HD 141399' 'HD 160691' 'HD 20781' 'HD 20794' 'HD 27894'\n",
      " 'HD 31527' 'HD 37124' 'HD 40307' 'HD 69830' 'tau Cet']\n"
     ]
    }
   ],
   "source": [
    "RV = data[\"discoverymethod\"] == \"Radial Velocity\"\n",
    "\n",
    "npl = np.array(data['sy_pnum'][RV], dtype=\"int\")\n",
    "Mstar = np.array(data['st_mass'][RV])\n",
    "Rstar = np.array(data['st_rad'][RV])\n",
    "starname = np.array(data['hostname'][RV])\n",
    "planetname = np.array(data['pl_name'][RV])\n",
    "\n",
    "print(\"\\n\\nMissing MASS\")\n",
    "print(np.unique(starname[(Mstar == '')*(npl > 2)]))\n",
    "\n",
    "print(\"\\n\\nMissing RADIUS\")\n",
    "print(np.unique(starname[(Rstar == '')*(npl > 2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Kepler names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepnamepath = MAINPATH + \"catalogues/kepler_names.txt\"\n",
    "\n",
    "# read in the stellar output parameters\n",
    "with open(kepnamepath, \"r\") as infile:\n",
    "    raw_kepnames = []\n",
    "    \n",
    "    for i, line in enumerate(infile):\n",
    "        raw_kepnames.append(line.split(\",\"))\n",
    "            \n",
    "raw_kepnames = np.array(raw_kepnames)\n",
    "\n",
    "# strip off trailing \\newline commands\n",
    "for i in range(len(raw_kepnames)):\n",
    "    raw_kepnames[i,-1] = raw_kepnames[i,-1].strip(\"\\n\").strip(\"\\ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepnames = {}\n",
    "\n",
    "for i, k in enumerate(raw_kepnames[0]):\n",
    "    kepnames[k] = raw_kepnames[1:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Gaia DR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaiapath = MAINPATH + \"catalogues/berger_2020_gaia_kepler_tab2_output.txt\"\n",
    "\n",
    "# read in the stellar output parameters\n",
    "with open(gaiapath, \"r\") as infile:\n",
    "    raw_gaia_data = []\n",
    "    \n",
    "    for i, line in enumerate(infile):\n",
    "        raw_gaia_data.append(line.split(\"&\"))\n",
    "            \n",
    "raw_gaia_data = np.array(raw_gaia_data)\n",
    "\n",
    "\n",
    "# strip off trailing \\newline commands\n",
    "for i in range(len(raw_gaia_data)):\n",
    "    raw_gaia_data[i,-1] = raw_gaia_data[i,-1].strip(\"\\n\").strip(\"\\ \")\n",
    "    \n",
    "    \n",
    "gaia_stars = {}\n",
    "\n",
    "for i, k in enumerate(raw_gaia_data[0]):\n",
    "    gaia_stars[k] = raw_gaia_data[1:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaiapath = MAINPATH + \"catalogues/berger_2020_gaia_kepler_planets.txt\"\n",
    "\n",
    "gaia_planets = {}\n",
    "\n",
    "gaia_planets[\"KIC\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=0)\n",
    "gaia_planets[\"radius\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=3)\n",
    "gaia_planets[\"radius_err1\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=4)\n",
    "gaia_planets[\"radius_err2\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=5)\n",
    "gaia_planets[\"sma\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=6)\n",
    "gaia_planets[\"sma_err1\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=7)\n",
    "gaia_planets[\"sma_err2\"] = np.loadtxt(gaiapath, skiprows=32, dtype=\"str\", usecols=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-match Kepler vs. Gaia and combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_kic = np.asarray(gaia_stars[\"KIC\"], dtype=\"int\")\n",
    "\n",
    "for i in range(len(data[k0])):\n",
    "    hostname = data[\"hostname\"][i]\n",
    "    \n",
    "    if hostname[:3] == \"Kep\":\n",
    "        \n",
    "        for j, kname in enumerate(kepnames[\"kepler_name\"]):\n",
    "            if kname[:-2] == hostname:\n",
    "                kic = int(kepnames[\"kepid\"][j])\n",
    "        \n",
    "        match = gaia_kic == kic\n",
    "        \n",
    "        if np.sum(match) == 1:\n",
    "            data[\"st_refname\"][i] = \"Berger et al. 2020\"\n",
    "            \n",
    "            data[\"st_teff\"][i] = gaia_stars[\"iso_teff\"][match][0]\n",
    "            data[\"st_tefferr1\"][i] = gaia_stars[\"iso_teff_err1\"][match][0]\n",
    "            data[\"st_tefferr1\"][i] = gaia_stars[\"iso_teff_err2\"][match][0]\n",
    "            data[\"st_tefflim\"][i]  = \"0\"\n",
    "            \n",
    "            data[\"st_rad\"][i] = gaia_stars[\"iso_rad\"][match][0]\n",
    "            data[\"st_raderr1\"][i] = gaia_stars[\"iso_rad_err1\"][match][0]\n",
    "            data[\"st_raderr1\"][i] = gaia_stars[\"iso_rad_err2\"][match][0]\n",
    "            data[\"st_radlim\"][i]  = \"0\"\n",
    "            \n",
    "            data[\"st_mass\"][i] = gaia_stars[\"iso_mass\"][match][0]\n",
    "            data[\"st_masserr1\"][i] = gaia_stars[\"iso_mass_err1\"][match][0]\n",
    "            data[\"st_masserr1\"][i] = gaia_stars[\"iso_mass_err2\"][match][0]\n",
    "            data[\"st_masslim\"][i]  = \"0\"\n",
    "            \n",
    "            data[\"st_met\"][i] = gaia_stars[\"iso_feh\"][match][0]\n",
    "            data[\"st_meterr1\"][i] = gaia_stars[\"iso_feh_err1\"][match][0]\n",
    "            data[\"st_meterr1\"][i] = gaia_stars[\"iso_feh_err2\"][match][0]\n",
    "            data[\"st_metlim\"][i]  = \"0\"\n",
    "            data[\"st_metratio\"][i]  = \"[Fe/H]\"\n",
    "            \n",
    "            data[\"st_logg\"][i] = gaia_stars[\"iso_logg\"][match][0]\n",
    "            data[\"st_loggerr1\"][i] = gaia_stars[\"iso_logg_err1\"][match][0]\n",
    "            data[\"st_loggerr1\"][i] = gaia_stars[\"iso_logg_err2\"][match][0]\n",
    "            data[\"st_logglim\"][i]  = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaia_kic = np.asarray(gaia_planets[\"KIC\"], dtype=\"int\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(len(data[k0])):\n",
    "    hostname = data[\"hostname\"][i]\n",
    "    \n",
    "    if hostname[:3] == \"Kep\":\n",
    "        \n",
    "        for j, kname in enumerate(kepnames[\"kepler_name\"]):\n",
    "            if kname[:-2] == hostname:\n",
    "                kic = int(kepnames[\"kepid\"][j])\n",
    "        \n",
    "        match = gaia_kic == kic\n",
    "        \n",
    "        if np.sum(match) == 1:\n",
    "            data[\"pl_rade\"][i] = gaia_planets[\"radius\"][match][0]\n",
    "            data[\"pl_radeerr1\"][i] = gaia_planets[\"radius_err1\"][match][0]\n",
    "            data[\"pl_radeerr1\"][i] = gaia_planets[\"radius_err2\"][match][0]\n",
    "            data[\"pl_radelim\"][i]  = \"0\"\n",
    "            \n",
    "            data[\"pl_radj\"][i] = str(np.round(float(gaia_planets[\"radius\"][match][0])*RERJ,3))\n",
    "            data[\"pl_radjerr1\"][i] = str(np.round(float(gaia_planets[\"radius_err1\"][match][0])*RERJ,3))\n",
    "            data[\"pl_radjerr1\"][i] = str(np.round(float(gaia_planets[\"radius_err2\"][match][0])*RERJ,3))\n",
    "            data[\"pl_radjlim\"][i]  = \"0\"\n",
    "            \n",
    "            \n",
    "            data[\"pl_orbsmax\"][i] = gaia_planets[\"sma\"][match][0]\n",
    "            data[\"pl_orbsmaxerr1\"][i] = gaia_planets[\"sma_err1\"][match][0]\n",
    "            data[\"pl_orbsmaxerr1\"][i] = gaia_planets[\"sma_err2\"][match][0]\n",
    "            data[\"pl_orbsmaxlim\"][i]  = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITENEW = True\n",
    "if WRITENEW:\n",
    "    filepath = MAINPATH + 'catalogues/oviraptor_crossmatch_catalog.csv'\n",
    "\n",
    "    with open(filepath, \"w\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(data.keys())\n",
    "        writer.writerows(zip(*data.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
